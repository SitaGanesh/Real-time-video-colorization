# ğŸ¨ Real-Time Video Colorization System

> **Transform black \& white videos into vibrant colorized content using AI and deep learning!**
***

## ğŸ¯ Project Overview

**Real-Time Video Colorization System** is an AI-powered application that can:

- âœ¨ **Colorize black \& white videos** in real-time using deep learning
- ğŸ¥ **Process live webcam feeds** with instant colorization
- ğŸ–¼ï¸ **Handle both video files and image frames**
- ğŸ¨ **Switch between different colorization models**
- ğŸ“± **User-friendly GUI** for easy interaction
- âš¡ **Real-time processing** with optimized performance


### ğŸ¯ Problem Statement

*"Create a model for colorizing grayscale video frames in real time. The model should be able to process video streams and live webcam feeds. A graphical user interface (GUI) should be provided to display colorized video in real time and allow users to switch between colorization models."*

### âœ… What This Project Does

| **Input** | **Process** | **Output** |
| :-- | :-- | :-- |
| Black \& White Video | AI Colorization | Colorized Video |
| Grayscale Webcam Feed | Real-time Processing | Live Colorized Stream |
| Color Video | Smart Detection | Preserved Original Colors |
| Image Frames | Batch Processing | Colorized Image Sequence |


***

## ğŸ—ï¸ Project Structure

```
semantic_video_colorization/
â”œâ”€â”€ ğŸ“ src/                          # Core source code
â”‚   â”œâ”€â”€ __init__.py                  # Package initialization
â”‚   â”œâ”€â”€ dataset.py                   # Dataset loading and preprocessing
â”‚   â”œâ”€â”€ inference.py                 # Real-time inference engine
â”‚   â”œâ”€â”€ train.py                     # Training pipeline
â”‚   â””â”€â”€ video_processor.py           # Video processing utilities
â”‚
â”œâ”€â”€ ğŸ“ models/                       # Neural network architectures
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ colorization_net.py         # Main colorization models
â”‚   â”œâ”€â”€ losses.py                    # Loss functions
â”‚   â””â”€â”€ utils.py                     # Model utilities
â”‚
â”œâ”€â”€ ğŸ“ config/                       # Configuration files
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ training_config.py          # Training hyperparameters
â”‚
â”œâ”€â”€ ğŸ“ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ download_pretrained.py      # Download pretrained models
â”‚   â”œâ”€â”€ evaluate_model.py           # Model evaluation
â”‚   â””â”€â”€ prepare_data.py             # Data preparation
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                    # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb   # Data analysis
â”‚   â”œâ”€â”€ 02_model_training.ipynb     # Training experiments
â”‚   â”œâ”€â”€ 03_inference_demo.ipynb     # Demo and testing
â”‚   â””â”€â”€ checkpoints/                # Saved model weights
â”‚
â”œâ”€â”€ ğŸ“ data/                         # Dataset directory
â”‚   â”œâ”€â”€ raw_videos/                  # Original video files
â”‚   â”œâ”€â”€ processed_frames/            # Extracted frames
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”‚   â”œâ”€â”€ grayscale/          # Training grayscale images
â”‚   â”‚   â”‚   â””â”€â”€ color/              # Training color images
â”‚   â”‚   â””â”€â”€ validation/
â”‚   â”‚       â”œâ”€â”€ grayscale/          # Validation grayscale images
â”‚   â”‚       â””â”€â”€ color/              # Validation color images
â”‚   â””â”€â”€ test_videos/                # Test video files
â”‚
â”œâ”€â”€ ğŸ“ checkpoints/                  # Trained model weights
â”‚   â”œâ”€â”€ fast_model.pth              # Fast inference model
â”‚   â”œâ”€â”€ hq_model.pth                # High-quality model
â”‚   â””â”€â”€ best_model.pth              # Best performing model
â”‚
â”œâ”€â”€ ğŸ“ screenshots/                  # GUI screenshots output
â”‚
â”œâ”€â”€ ğŸ gui.py                       # Main GUI application
â”œâ”€â”€ ğŸ“‹ requirements.txt             # Python dependencies
â”œâ”€â”€ ğŸ”§ setup.py                     # Package setup
â”œâ”€â”€ ğŸ“– README.md                    # This file
â””â”€â”€ ğŸ“„ .gitignore                   # Git ignore rules
```


***

## ğŸš€ Quick Start

### âš¡ For Impatient Users

```bash
# 1. Clone and setup
git clone https://github.com/SitaGanesh/Real-time-video-colorization.git
cd Real-time-video-colorization
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# 2. Install and run
pip install -r requirements.txt
python gui.py

# 3. Load a black & white video and watch the magic! âœ¨
```


***

## ğŸ’» Installation \& Setup

### ğŸ“‹ Prerequisites

- **Python 3.8+** (3.9 recommended)
- **CUDA-capable GPU** (optional, for faster processing)
- **4GB+ RAM** (8GB+ recommended)
- **Windows 10/11, Linux, or macOS**


### ğŸ”§ Step-by-Step Installation

#### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/SitaGanesh/Real-time-video-colorization.git
cd Real-time-video-colorization
```


#### 2ï¸âƒ£ Create Virtual Environment

**Windows:**

```bash
python -m venv venv
venv\Scripts\activate
```

**Linux/macOS:**

```bash
python3 -m venv venv
source venv/bin/activate
```


#### 3ï¸âƒ£ Install Dependencies

```bash
# Upgrade pip first
python -m pip install --upgrade pip

# Install all requirements
pip install -r requirements.txt

# For CUDA support (optional)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```


#### 4ï¸âƒ£ Verify Installation

```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import cv2; print(f'OpenCV: {cv2.__version__}')"
```


#### 5ï¸âƒ£ Download Pretrained Models (Optional)

```bash
python scripts/download_pretrained.py
```


#### 6ï¸âƒ£ Create Required Directories

```bash
mkdir -p data/raw_videos data/test_videos screenshots checkpoints
```


***

## ğŸ“Š Usage Guide

### ğŸ® GUI Interface (Recommended for Beginners)

#### **Step 1: Launch the GUI**

```bash
python gui.py
```


#### **Step 2: Choose Processing Mode**

- ğŸ¨ **Demo Mode**: Rule-based colorization (works immediately)
- ğŸ§  **Neural Mode**: AI model colorization (requires trained model)


#### **Step 3: Load Your Content**

- **ğŸ“¹ Webcam**: Click "Start Webcam" for live processing
- **ğŸ¬ Video File**: Click "Load Video" and select your file


#### **Step 4: Watch the Magic!**

- **Black \& White Input** â†’ **Colorized Output** âœ¨
- **Color Input** â†’ **Preserved Original Colors** ğŸŒˆ


#### **Step 5: Save Results**

- **ğŸ“¸ Screenshot**: Save current colorized frame
- **ğŸ’¾ Location**: `screenshots/colorized_screenshot_[timestamp].png`


### ğŸ““ Jupyter Notebooks (For Experimentation)

#### **Start Jupyter Lab**

```bash
jupyter lab
```


#### **Navigate to Notebooks**

1. **ğŸ“Š `01_data_exploration.ipynb`**: Analyze your video data
2. **ğŸ‹ï¸ `02_model_training.ipynb`**: Train colorization models
3. **ğŸ¯ `03_inference_demo.ipynb`**: Test and demo models

### ğŸ–¥ï¸ Command Line Interface

#### **Process Single Video**

```bash
python -m src.inference --input data/test_videos/bw_video.mp4 --output colorized_output.mp4
```


#### **Train New Model**

```bash
python src/train.py --data-dir data/processed_frames --epochs 50 --batch-size 16
```


#### **Evaluate Model**

```bash
python scripts/evaluate_model.py --model checkpoints/best_model.pth --data data/processed_frames
```


***

## ğŸ”§ File Descriptions

### ğŸ“ **Core Source Code (`src/`)**

| File | Purpose | What It Does |
| :-- | :-- | :-- |
| **`dataset.py`** | Data Pipeline | Loads video frames, applies transforms, creates train/val splits |
| **`inference.py`** | Real-time Engine | Processes video streams, handles model inference, performance tracking |
| **`train.py`** | Training Pipeline | Complete training loop, checkpointing, validation, early stopping |
| **`video_processor.py`** | Video Utilities | Extract frames, create videos, format conversions, metadata |

### ğŸ§  **Models (`models/`)**

| File | Purpose | What It Does |
| :-- | :-- | :-- |
| **`colorization_net.py`** | Neural Networks | U-Net, FastNet, Attention-based colorization architectures |
| **`losses.py`** | Loss Functions | L1, Perceptual, GAN losses for training |
| **`utils.py`** | Model Utilities | Weight initialization, model summaries, utilities |

### âš™ï¸ **Configuration (`config/`)**

| File | Purpose | What It Does |
| :-- | :-- | :-- |
| **`training_config.py`** | Hyperparameters | Learning rates, batch sizes, model settings, paths |

### ğŸ› ï¸ **Scripts (`scripts/`)**

| File | Purpose | What It Does |
| :-- | :-- | :-- |
| **`download_pretrained.py`** | Model Downloader | Downloads pretrained weights from online sources |
| **`evaluate_model.py`** | Model Evaluation | Tests model performance, generates metrics, sample outputs |
| **`prepare_data.py`** | Data Preparation | Extracts frames from videos, creates train/val splits |

### ğŸ“š **Notebooks (`notebooks/`)**

| Notebook | Purpose | What You'll Learn |
| :-- | :-- | :-- |
| **`01_data_exploration.ipynb`** | Data Analysis | Video statistics, frame distributions, quality analysis |
| **`02_model_training.ipynb`** | Training Process | Model architecture, training loops, loss visualization |
| **`03_inference_demo.ipynb`** | Testing \& Demo | Model inference, result comparison, performance analysis |

### ğŸ® **Main Application**

| File | Purpose | What It Does |
| :-- | :-- | :-- |
| **`gui.py`** | Main Interface | Complete GUI application with real-time video processing |


***

## ğŸ§  How It Works

### ğŸ”„ **Processing Pipeline**

```mermaid
graph LR
    A[Input Video] --> B{Detect Type}
    B -->|Grayscale| C[AI Colorization]
    B -->|Color| D[Preserve Original]
    C --> E[Neural Network]
    E --> F[Color Prediction]
    F --> G[Post-processing]
    G --> H[Display Result]
    D --> H
```


### ğŸ¯ **Core Algorithm**

1. **ğŸ” Frame Analysis**: Detect if input is grayscale or color
2. **ğŸ¨ Colorization Process** (for grayscale frames):
    - Convert frame to tensor
    - Normalize pixel values
    - Pass through neural network
    - Generate RGB color channels
    - Apply post-processing
3. **ğŸ“º Display**: Show colorized result in real-time
4. **ğŸ’¾ Storage**: Save screenshots of colorized frames

### ğŸ§¬ **Neural Network Architecture**

```python
Input: Grayscale Frame [1 x H x W]
    â†“
Encoder: Extract Features
    â†“ 
Bottleneck: Process Features
    â†“
Decoder: Generate Colors
    â†“
Output: RGB Frame [3 x H x W]
```


### âš¡ **Performance Optimization**

- **GPU Acceleration**: CUDA support for faster processing
- **Batch Processing**: Process multiple frames simultaneously
- **Memory Management**: Efficient tensor operations
- **Threading**: Separate threads for GUI and processing

***

## ğŸ® GUI Interface

### ğŸ–¥ï¸ **Main Window Components**

#### **ğŸ›ï¸ Control Panel**

- **ğŸ“¹ Start Webcam**: Begin live camera colorization
- **ğŸ¬ Load Video**: Select video file for processing
- **â¹ï¸ Stop**: End current processing
- **ğŸ“¸ Screenshot**: Save current colorized frame
- **ğŸ¨ Mode Toggle**: Switch between Demo/Neural modes
- **âŒ Exit**: Close application


#### **ğŸ“º Video Display**

- **640x480 pixels** main viewing area
- **Real-time preview** of colorization results
- **Status indicators** for current processing state


#### **â„¹ï¸ Status Bar**

- **Processing status**: Current operation state
- **FPS counter**: Real-time performance metrics
- **Debug information**: Technical details for troubleshooting


### ğŸ¨ **Processing Modes**

#### **ğŸ¨ Demo Mode**

- **Rule-based colorization** using image analysis
- **No trained model required**
- **Instant results** with basic color assignment
- **Perfect for testing** and demonstrations


#### **ğŸ§  Neural Mode**

- **AI-powered colorization** using trained deep learning models
- **High-quality results** with realistic colors
- **Requires trained model** weights
- **Best for production** use


### ğŸ“¸ **Screenshot Feature**

- **Automatic saving** to `screenshots/` directory
- **Timestamped filenames** for organization
- **PNG format** for high quality
- **Includes colorized result**, not original grayscale

***

## ğŸ“š Training Your Own Model

### ğŸ“Š **Data Preparation**

#### **Step 1: Collect Videos**

```bash
# Place your training videos in:
data/raw_videos/
â”œâ”€â”€ video1.mp4
â”œâ”€â”€ video2.avi
â””â”€â”€ video3.mov
```


#### **Step 2: Extract Frames**

```bash
python scripts/prepare_data.py \
    --input data/raw_videos \
    --output data/processed_frames \
    --frame-rate 1.0 \
    --max-frames 500 \
    --target-size 256x256
```


#### **Step 3: Verify Data**

```bash
# Check extracted frames
ls data/processed_frames/train/grayscale/ | wc -l
ls data/processed_frames/train/color/ | wc -l
```


### ğŸ‹ï¸ **Training Process**

#### **Step 1: Configure Training**

Edit `config/training_config.py`:

```python
class TrainingConfig:
    DATA_DIR = 'data/processed_frames'
    BATCH_SIZE = 16
    LEARNING_RATE = 0.0001
    NUM_EPOCHS = 100
    MODEL_NAME = 'ColorizationNet'
```


#### **Step 2: Start Training**

```bash
python src/train.py \
    --data-dir data/processed_frames \
    --epochs 50 \
    --batch-size 16 \
    --model FastColorizationNet
```


#### **Step 3: Monitor Progress**

```bash
# View training logs
tensorboard --logdir logs/
```


#### **Step 4: Evaluate Results**

```bash
python scripts/evaluate_model.py \
    --model checkpoints/best_model.pth \
    --data data/processed_frames
```


### ğŸ“ˆ **Training Tips**

- **ğŸ¯ Start Small**: Use 1000-5000 frames for initial experiments
- **âš–ï¸ Balance Data**: Equal amounts of different scene types
- **ğŸ” Monitor Overfitting**: Use validation loss for early stopping
- **ğŸ’¾ Save Checkpoints**: Regular model saving during training
- **ğŸ¨ Visual Inspection**: Check sample colorizations regularly

***

## ğŸ”¬ Technical Details

### ğŸ§® **Model Architectures**

#### **FastColorizationNet**

- **Purpose**: Real-time processing
- **Layers**: 4 encoder + 4 decoder
- **Parameters**: ~2M
- **Speed**: 30+ FPS on GPU
- **Quality**: Good for live streams


#### **ColorizationNet**

- **Purpose**: High-quality results
- **Layers**: 8 encoder + 8 decoder
- **Parameters**: ~15M
- **Speed**: 10-15 FPS on GPU
- **Quality**: Excellent for offline processing


#### **AttentionColorizationNet**

- **Purpose**: State-of-the-art quality
- **Features**: Self-attention mechanisms
- **Parameters**: ~25M
- **Speed**: 5-8 FPS on GPU
- **Quality**: Best possible results


### âš™ï¸ **System Requirements**

#### **Minimum Requirements**

- **CPU**: Intel i5 / AMD Ryzen 5
- **RAM**: 4GB
- **GPU**: Integrated graphics
- **Storage**: 2GB free space
- **Performance**: 5-10 FPS


#### **Recommended Requirements**

- **CPU**: Intel i7 / AMD Ryzen 7
- **RAM**: 8GB+
- **GPU**: GTX 1060 / RTX 2060 / RTX 3060
- **Storage**: 10GB free space
- **Performance**: 20-30 FPS


#### **Optimal Requirements**

- **CPU**: Intel i9 / AMD Ryzen 9
- **RAM**: 16GB+
- **GPU**: RTX 3080 / RTX 4080 / RTX 4090
- **Storage**: 20GB+ SSD
- **Performance**: 60+ FPS


### ğŸ”§ **Performance Optimization**

#### **GPU Optimization**

```python
# Enable GPU acceleration
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = model.to(device)

# Mixed precision training
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()
```


#### **Memory Management**

```python
# Clear cache regularly
torch.cuda.empty_cache()

# Use efficient data loading
DataLoader(dataset, pin_memory=True, num_workers=4)
```


#### **Inference Optimization**

```python
# Disable gradients for inference
with torch.no_grad():
    output = model(input_tensor)

# Use half precision
model.half()  # Reduce memory usage by 50%
```


***



## ğŸ› Troubleshooting

### âŒ **Common Issues \& Solutions**

#### **ğŸš« "Cannot open webcam"**

```bash
# Solution 1: Check camera permissions
# Windows: Settings â†’ Privacy â†’ Camera
# Linux: ls /dev/video*
# Mac: System Preferences â†’ Security & Privacy

# Solution 2: Try different camera index
camera_idx = 1  # Instead of 0
```


#### **ğŸš« "Model file not found"**

```bash
# Solution: Download or create model file
python scripts/download_pretrained.py
# Or use demo mode
```


#### **ğŸš« "CUDA out of memory"**

```python
# Solution: Reduce batch size
BATCH_SIZE = 8  # Instead of 16
# Or use CPU
device = 'cpu'
```


#### **ğŸš« "Video file cannot be opened"**

```bash
# Solution: Check supported formats
# Supported: .mp4, .avi, .mov, .mkv, .wmv
# Convert if needed:
ffmpeg -i input.video -c:v libx264 output.mp4
```


#### **ğŸš« "Poor colorization quality"**

```bash
# Solution 1: Use higher quality model
model = 'AttentionColorizationNet'

# Solution 2: Train on similar data
python src/train.py --data-dir your_data

# Solution 3: Adjust preprocessing
target_size = (512, 512)  # Higher resolution
```


### ğŸ”§ **Debug Mode**

#### **Enable Detailed Logging**

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```


#### **Check System Info**

```python
python -c "
import torch, cv2, sys
print(f'Python: {sys.version}')
print(f'PyTorch: {torch.__version__}')
print(f'CUDA: {torch.cuda.is_available()}')
print(f'OpenCV: {cv2.__version__}')
"
```



***

## ğŸ“Š Project Statistics

- **ğŸ“… Created**: 2025
- **ğŸš€ Version**: 1.0.0
- **ğŸ“ Language**: Python 3.8+
- **ğŸ§  Framework**: PyTorch
- **ğŸ¨ GUI**: CustomTkinter
- **ğŸ“¹ Video**: OpenCV
- **â­ Stars**: Growing!

***

## ğŸ”® Future Roadmap

- [ ] **ğŸ¬ Real-time video export** functionality
- [ ] **ğŸŒ Web interface** for browser-based usage
- [ ] **ğŸ“± Mobile app** for iOS and Android
- [ ] **â˜ï¸ Cloud processing** for high-end models
- [ ] **ğŸ¨ Style transfer** integration
- [ ] **ğŸ¤– Automatic model selection** based on content
- [ ] **ğŸ“ˆ Advanced metrics** and quality assessment
- [ ] **ğŸ”„ Batch video processing** for multiple files

***

<div align="center">

### ğŸ‰ **Ready to Start Colorizing?**

```bash
git clone https://github.com/SitaGanesh/Real-time-video-colorization.git
cd Real-time-video-colorization
pip install -r requirements.txt
python gui.py
```


</div>

***

Happy Colorizing

***
*Made with â¤ï¸ by the Sita Ganesh*

